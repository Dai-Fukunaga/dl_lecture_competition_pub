{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "import hydra\n",
    "from omegaconf import DictConfig\n",
    "import wandb\n",
    "from termcolor import cprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.datasets import ThingsMEGDataset\n",
    "from src.densenet import DenseNetClassifier\n",
    "from src.resnet2d import resnet50_2d\n",
    "from src.resnet1d import resnet50_1d\n",
    "\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from src.utils import set_seed\n",
    "from scipy.signal import butter, sosfiltfilt\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパーパラメータの設定\n",
    "args = DictConfig({\n",
    "    'seed': 1234,\n",
    "    'data_dir': '/mnt/mp_nas_mks/labmember/d.fukunaga/data',\n",
    "    'batch_size': 128,\n",
    "    'num_workers': 8,\n",
    "    'lr': 0.001,\n",
    "    'epochs': 30,\n",
    "    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'use_wandb': False\n",
    "})\n",
    "\n",
    "set_seed(args.seed)\n",
    "logdir = 'outputs'\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb.init(mode=\"online\", dir=logdir, project=\"MEG-classification\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "class ResampleTransform:\n",
    "    def __init__(self, orig_freq, new_freq):\n",
    "        self.resample = T.Resample(orig_freq, new_freq)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return self.resample(x)\n",
    "\n",
    "class BandpassFilterTransform:\n",
    "    def __init__(self, low_cutoff, high_cutoff, fs, order=5):\n",
    "        self.sos = butter(order, [low_cutoff / (0.5 * fs), high_cutoff / (0.5 * fs)], btype='band', output='sos')\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x_np = np.ascontiguousarray(x.detach().cpu().numpy())  # NumPy配列を連続配列としてコピー\n",
    "        filtered = sosfiltfilt(self.sos, x_np, axis=-1)  # axisを指定してフィルタを適用\n",
    "        return torch.tensor(filtered, dtype=torch.float32, device=x.device)  # 元のデバイスに戻す\n",
    "\n",
    "class NormalizeTransform:\n",
    "    def __call__(self, x):\n",
    "        return (x - x.mean(dim=-1, keepdim=True)) / x.std(dim=-1, keepdim=True)\n",
    "\n",
    "# 複合transform\n",
    "wave_transforms = Compose([\n",
    "    ResampleTransform(orig_freq=1000, new_freq=128),\n",
    "    # BandpassFilterTransform(low_cutoff=1, high_cutoff=40, fs=128),\n",
    "    NormalizeTransform()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "#    Dataloader\n",
    "# ------------------\n",
    "loader_args = {\"batch_size\": args.batch_size, \"num_workers\": args.num_workers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = ThingsMEGDataset(\"train\", args.data_dir, transforms=wave_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_set = ThingsMEGDataset(\"val\", args.data_dir, transforms=wave_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, shuffle=False, **loader_args)\n",
    "test_set = ThingsMEGDataset(\"test\", args.data_dir, transforms=wave_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_set,\n",
    "    shuffle=False,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4431, -2.0549, -0.5833,  ...,  1.7070,  0.8035,  0.0636],\n",
       "         [-0.6210, -2.2190, -0.6947,  ...,  1.4975,  0.3503,  0.7291],\n",
       "         [-0.7366, -2.4049, -0.9725,  ...,  1.0039, -0.1360,  0.9885],\n",
       "         ...,\n",
       "         [-1.1306,  1.4246,  0.3441,  ..., -0.6665,  0.9779,  0.3473],\n",
       "         [ 0.9576,  0.8476,  1.3057,  ..., -1.2348,  0.7442, -0.0424],\n",
       "         [-1.8650, -0.2206, -0.7674,  ...,  0.8498,  0.2762,  0.7946]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------\n",
    "#       Model\n",
    "# ------------------\n",
    "# model = DenseNetClassifier(\n",
    "#     train_set.num_classes, train_set.seq_len, train_set.num_channels\n",
    "# ).to(args.device)\n",
    "\n",
    "model = resnet50_1d(\n",
    "    num_classes=train_set.num_classes, in_channels=train_set.num_channels\n",
    ").to(args.device)\n",
    "\n",
    "# ------------------\n",
    "#     Optimizer\n",
    "# ------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# スケジューラ―\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# ------------------\n",
    "#   Start training\n",
    "# ------------------\n",
    "max_val_acc = 0\n",
    "accuracy = Accuracy(\n",
    "    task=\"multiclass\", num_classes=train_set.num_classes, top_k=10\n",
    ").to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from tqdm import tqdm\n",
    "\n",
    "# # CUDAの設定を確認・調整\n",
    "cudnn.enabled = False\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# トレーニングループ\n",
    "max_val_acc = 0\n",
    "accuracy = Accuracy(task=\"multiclass\", num_classes=train_set.num_classes, top_k=10).to(args.device)\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    print(f\"Epoch {epoch+1}/{args.epochs}\")\n",
    "\n",
    "    train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "\n",
    "    model.train()\n",
    "    for X, y, subject_idxs in tqdm(train_loader, desc=\"Train\"):\n",
    "        X, y, subject_idxs = X.to(args.device), y.to(args.device), subject_idxs.to(args.device)\n",
    "        # print(f\"Input shape: {X.shape}\")\n",
    "        # print(f\"Subject indices shape: {subject_idxs.shape}\")\n",
    "\n",
    "        try:\n",
    "            X = X.clone().detach()\n",
    "            subject_idxs = subject_idxs.clone().detach()\n",
    "\n",
    "            y_pred = model(X, subject_idxs)\n",
    "\n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            train_loss.append(loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc = accuracy(y_pred, y)\n",
    "            train_acc.append(acc.item())\n",
    "        except RuntimeError as e:\n",
    "            print(f\"RuntimeError: {e}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "\n",
    "    model.eval()\n",
    "    for X, y, subject_idxs in tqdm(val_loader, desc=\"Validation\"):\n",
    "        X, y, subject_idxs = X.to(args.device), y.to(args.device), subject_idxs.to(args.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X, subject_idxs)\n",
    "\n",
    "        val_loss.append(F.cross_entropy(y_pred, y).item())\n",
    "        val_acc.append(accuracy(y_pred, y).item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{args.epochs} | train loss: {np.mean(train_loss):.3f} | train acc: {np.mean(train_acc):.3f} | val loss: {np.mean(val_loss):.3f} | val acc: {np.mean(val_acc):.3f}\")\n",
    "    torch.save(model.state_dict(), os.path.join(logdir, \"model_last.pt\"))\n",
    "    if args.use_wandb:\n",
    "        wandb.log({\n",
    "            \"train_loss\": np.mean(train_loss),\n",
    "            \"train_acc\": np.mean(train_acc),\n",
    "            \"val_loss\": np.mean(val_loss),\n",
    "            \"val_acc\": np.mean(val_acc),\n",
    "        })\n",
    "\n",
    "    if np.mean(val_acc) > max_val_acc:\n",
    "        cprint(\"New best.\", \"cyan\")\n",
    "        torch.save(model.state_dict(), os.path.join(logdir, \"model_best.pt\"))\n",
    "        max_val_acc = np.mean(val_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 129/129 [00:02<00:00, 48.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mSubmission (16432, 1854) saved at outputs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ベストモデルでの評価\n",
    "model.load_state_dict(torch.load(os.path.join(logdir, \"model_best.pt\"), map_location=args.device))\n",
    "\n",
    "preds = []\n",
    "model.eval()\n",
    "for X, subject_idxs in tqdm(test_loader, desc=\"Validation\"):\n",
    "    with torch.no_grad():\n",
    "        pred = model(X.to(args.device), subject_idxs.to(args.device))\n",
    "    preds.append(pred.detach().cpu())\n",
    "\n",
    "preds = torch.cat(preds, dim=0).numpy()\n",
    "np.save(os.path.join(logdir, \"submission\"), preds)\n",
    "cprint(f\"Submission {preds.shape} saved at {logdir}\", \"cyan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlbasics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
